This is what remains to be done on  unifill


[x] Grep backend

    The idea is to give up some of the ranking sophistication and gain less
    code and much faster speeds, by replacing the custom lua code with
    telescope's builtin grep and fuzzy finding.

    If the results seem promising (that is we get a nice result that's very
    fast) we may consider using a two pass algo to fine tune ranking a small
    subset of items.

[x] Verify aliases

    While we are downloading the alias, I've yet to see it show up on  any
    result item, so we should check that we're matching the code-point dataset
    to the alias one correctly.


[ ] Improve theming

    We're skinning the telescope UI, but we're doing it in a blind way, for
    example by setting text to black regardless of a user's theme.
    The right way to do this is more like use entities (like emphasis text) or
    light background that will be configured on the user's theme, so this can
    be integrated and work regardless of user theming.


[ ] Verify plugin setup
    We did a quick throwaway thing for the setup, now it's time  to make sure
    that the plugin is ready for distribution: 
        - is the file layout looking good? 
        - do we follow plugin design best practices? If not, what's to be
          changed? 
        - what about the entire dataset generation thing? this shouldnt be
          redistributed. also, should we have the dataset be in git or the
          plugin load it from a zip at load time 


[]  Install from github

    When that is all done, we can ditch the local install and test the regular
    github based install


[ ] Frequently used
    Currently we're showing / ranking lexicographically all characters. IRL  ,
    people will use a subset of these much  more often. 
    We could generate a frequently used ranking and reserve the top 5 places
    for these, both at cold start (no search query term is entered) and when
        sorting results (that is, if a frequently used one is part of the
        results, it should be bumped up)


[x ] All Unicode, really? 

    Currently we process all unicode chars, in their full glory. But do we need
    to?  The most obvious use case if people wanting a nice arrow, greek
    symbol, stuff like that. 
    We could generate two data sets: classic and unabridged. Default to classic
    but could be changed to unabridged.
    

[ ] Embellish Me
    
    Instead of typing / inserting all unicode, have a unicodize this command
    that search the buffer for good candidates and in a search and replace
    sequence like thing proposes changes, like changing PI to ፲ , or -> to →. 

    Is there a good mapping of these? Of course we could let users add their
    own via config .
